# 파이썬 크롤링과 스크레이핑

## 1. urllib으로 웹페이지 추출하기

* 웹페이지 추출할 때는 표준 라이브러리 urllib.request 모듈을 사용합니다.

|             함수명 / 필드명              |                             기능                             |     입력값      |                            반환값                            |
| :--------------------------------------: | :----------------------------------------------------------: | :-------------: | :----------------------------------------------------------: |
|                urlopen()                 |                        url을 가져온다                        |     url경로     |                  HTTPResponse객체->파일객체                  |
|           HTTPResponse.read()            |                 HTTP 응답 본문을 추출합니다.                 |        -        |                         bytes 자료형                         |
|           HTTPResponse.status            |                    상태코드를 추츨합니다.                    |                 |                           ex) 200                            |
|  HTTPResponse.getheader('Content-type')  |                 HTTP 헤더의 값을 추출합니다.                 |   출력 변수명   | 헤더의 내용을 변경하려거나 Basic인증 사용하려면  Requests 서드파티 라이브러리 필요 |
|           HTTPResponse.info()            |              HTTPResponse헤더의 전반적정보 출력              |                 |                       HTTPMessage객체                        |
| HTTPMessage.get_content_charset(failobj) | HTTP헤더를 기반으로 인코딩 방식 출력. 헤더에 해당 변수 값이 없는 경우 failobj문자열을반환 | failobj='utf-8' |                                                              |

## 2. 문자코드 다루기

- HTTPResponse.read()로 추출할 수 있는 응답본문의 값은 bytes자료형이므로 문자열(str자료형)으로 다루려면 문자코드를 지정해야한다.
- HTTP헤더에서 Content-type 헤더를 참조하면 해당 페이지에서 사용되고 있는 인코딩 방식을 알아낼 수 있습니다.
  - text/html
  - text/html; charset=UTF-8
  - text/html; charset=EUC-KR
  - charset= 뒤에 적혀 있는 문자열이 인코딩 방식입니다. default는 UTF-8
  - HTTPResponse.info()

## 3. meta 태그에서 인코딩 방식 추출하기

- HTTP헤더 인코딩 정보(웹서버 설정)와 실제 인코딩 형식이 다른경우

- 매타태크 또는 응답본문의 바이트 열도 확인해서 최종적인 인코딩 방식을 결정

  #meta태그의 charset 값에서 인코딩 방식을 추출한다.

  <meta charset="utf-8"></meta>
  <meta http-equiv="Content-Type" content="tent/html"; charset="EUC_KR"></meta>

  ```python
  scanned_text = bytes_content[:1024].decode('ascii',errors='replace')
  #응답 본문 앞부분 1024바이트를 ASCII문자로 디코딩해 둡니다.
  
  match = re.search(r'charset = ["\']\?([\w-]+)', scanned_text)
  #정규표현식으로 해당하는 charset값 추출
  
  if match: #해당 객체가 있다면
      encoding = match.group(1)
  else:
      encoding = 'utf-8'
  
  ```



## 4. 웹페이지에서 데이터 추출하기(스크레이핑)

* 정규표현식
  * HTML을 단순한 문자열 취급, 필요한 부분을 추출 합니다.
  * 제대로 마크업되지 않은 페이지도 문자열특징을 파악하여 쉽게 스크레이핑 가능
* XML파서
  * XML태그를 분석(파싱)하고, 필요한 부분만 추출합니다.
  * 블로그, 뉴스 사이트 정보를 전달하는 RSS처럼 많은 정보가 XML로 전달됩니다.
  * XML은 HTML보다 유연성이 떨어져 XML파서에 곧장 HTML을 넣어 분석은 불가능하다.

### 1. 정규표현식으로 스크레이핑 하기

* 표준 라이브러리 re 모듈을 사용한다.

* raw문자열이라 불리는(r'...')형식의 문자열 리터럴 사용하면 백슬레시가 이스케이프 문자로 사용되지 않습니다.

* ```python
  p = re.compile('ab*')
  #정규표현식을 컴파일
  #컴파일된 패턴 객체를 리턴
  ```

* 패턴객체 4가지 메서드

| 함수명 / 필드명 | 기능 | 입력값 | 반환값 |
| :---------: | :-----: | :----: | :----: |
| Pattern.match(str)  |        문자열의 처음부터 패턴과 매치되는지 조사한다.         |  str   | match / None<br>처음부터 일치하는지 검사하고 아니면 곧바로 return None |
| Pattern.search(str) |      문자열 전체를 검색하여 패턴과 매치되는지 조사한다.      |  str   | match / None<br>문자열 전체에서 검사하지만 제일처음 패턴과 매치되면 그 문자열과 매치된 정보만 가진 match만 return |
|  Pattern.findall()  |      정규식과 매치되는 모든 문자열을 리스트로 돌려준다       |  str   |                            리스트                            |
|  Patter.finditer()  | 정규식과 매치되는 모든 문자열을 반복 가능한 객체로 돌려준다. |  str   |           반복가능객체(match객체를 원소로 가진다.)           |

## match 객체의 메서드

자, 이제 match 메서드와 search 메서드를 수행한 결과로 돌려준 match 객체에 대해 알아보자. 앞에서 정규식을 사용한 문자열 검색을 수행하면서 아마도 다음과 같은 궁금증이 생겼을 것이다.

- 어떤 문자열이 매치되었는가?
- 매치된 문자열의 인덱스는 어디서부터 어디까지인가?



match 객체의 메서드를 사용하면 이 같은 궁금증을 해결할 수 있다. 다음 표를 보자.

| method  | 목적                                                   |
| :------ | :----------------------------------------------------- |
| group() | 매치된 문자열을 돌려준다.                              |
| start() | 매치된 문자열의 시작 위치를 돌려준다.                  |
| end()   | 매치된 문자열의 끝 위치를 돌려준다.                    |
| span()  | 매치된 문자열의 (시작, 끝)에 해당하는 튜플을 돌려준다. |



## User-Agent

- user-agent : 사용자를 대신해서 일을 수행하는 소프트웨어 에이전트(web-browser)
- 요즘 웹사이트는 대부분 PC버전의 웹사이트, 모바일 버전의 웹 사이트를 별도로 분리해서 개발
- 특정 웹사이트는 웹서버의 부하 방지를 위해  파이썬 관련 user-agent를 차단하곤 한다.
- 특정 웹사이트에서 위와 같이 User-Agent를 막고 있다면 User-Agent값을 조작해서 우회 할 수 있어야 합니다.
- headers = {"User-Agent":"~"}
- res = request.get(url, headers=headers)
- 단 직접 브라우저를 웹 크롤링을 한다면 User-Agent를 변경할 필요가 없다.
