[toc]

# 분류 모델

## 1. 분류 알고리즘 선택

특정 문제에 알맞는 분류 알고리즘을 선택하려면 연습과 경험이 필요합니다. 알고리즘은 저마다 특징이 있고 일정한 가정을 전제로 합니다.

모델의 성능은 특성이나 샘플의 개수에 따라 다르고 데이터 셋에 있는 잡음 데이터 양과 클래스가 선형적으로 구분 되는 지 아닌지에 따라서도 다를 것 입니다.

**결국 분류모델의 예측 성능과 계산 성능은 학습에 사용하려는 데이터에 크게 의존합니다.**

머신러닝 알고리즘을 훈련시키기 위한 다섯가지 단계

1. 특성을 선택하고 훈련 샘플을 모읍니다.

2. **성능 지표를 선택합니다.**
3. 분류 모델과 최적화 알고리즘을 선택합니다.
4. 모델의 성능을 평가합니다.
5. 알고리즘을 튜닝합니다.



## 2. 사이킷런 첫걸음 : 퍼셉트론 훈련

사용하기 쉬운 인터페이스로 분류 알고리즘 최적화하여 구현한 사이킷런 API를 통한 학습

사이킷런은 많은 학습 알고리즘을 제공할 뿐만 아니라. 데이터 전처리나 세부 조정, 모델 평가를 위해 편리하게 사용할 수 있는 많은 학습 알고리즘이 있습니다.

```python
from sklearn import datasets
import numpy as np

iris = datasets.load_iris()
```



사이킷런의 많은 함수와 클래스 메서드는 문자열 형태(비정형데이터) 클래스 레이블을 다룰 수 있습니다. => LabelEncoder, OvR(One versus Rest)로 정수 인코딩

정수레이블이 권장되는 이유 : 사소한 실수를 피할수 있고 작은 메모리 영역을 차지하므로 계산 성능을 향상시키기 때문이니다. 고로 클레스 레이블을 정수로 인코딩 하는 것은 대부분 머신러닝 라이브러리들의 관례이다.

처음 본 데이터에서 학습된 모델을 평가하기 위해 데이터셋을 훈련 데이터셋와 테스트 데이터셋으로 분할

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)
#random_state에 랜덤시드 지정시 실행결과를 재현할 수 있습니다.
# 나눠진 데이터셋의 레이블 비율이 입력(특성행렬) 데이터셋과 동일
print('y의 클래스 레이블 카운트 : ',np.bincount(y))
print('y_train의 클래스 레이블 카운트 : ',np.bincount(y_train))
print('y_train의 클래스 레이블 카운트 : ',np.bincount(y_test))
```

train_test_split 함수가 분할하기 전에 데이터셋을 미리 섞습니다. => 아니면 클래스 0과 1에 있는 샘플이 모두 훈련 데이터셋에 들어가므로 과대적합이 생길수 있다.

stratify=y를 통해 계층화 기능을 사용. train_test_split함수가 훈련 데이터셋과 테스트 데이터셋의 클래스 레이블의 비율을 입력 데이터셋과 동일하게 만든다는 의미입니다.

많은 머신러닝 알고리즘은 최적화 알고리즘을 위해 특성 스케일 조정(표준화)이 필요하다.

특성 표준화를 위해서 preprocessing모듈의 StandardScaler를 사용한다.

` StandardScaler` 객체의 fit메소드는 훈련 데이터셋의 각 특성 차원마다 평균과 표준편차를 계산

 `StandardScaler.transform`메소드는 계산돤 평균과 표준편차를 사용하여 데이터셋을 표준화

테스트데이터셋의 샘플들도 같은 비율로 이동하도록  동일 mean과 std 적용하여 표준화

```python
from sklearn.preprocessing import StandardScaler
#표준화 객체 생성
sc=StandardScaler()
#표준화 객체의 fit메소드는 훈련 데이터셋의 각 특성 차원마다 평균과 표준편차를 계산
sc.fit(X_train)
#데이터셋 표준화
X_train_std = sc.transform(X_train)
X_test_std = sc.transform(X_test)
```

```python
from sklearn.linear_model import Perceptron
ppn= Perceptron(eta0=0.1, random_state=1)
#퍼셉트론 객체에 훈련데이터 학습
ppn.fit(X_train_std,y_train)
```

적절한 학습률을 찾으려면 어느 정도 실험이 필요합니다. **학습률이 너무 크면 알고리즘은 전역 최솟값을 지나칩니다. 너무 작으면 학습 속도가 느리기 때문에 특히 대규모 데이터셋에서 수렴하기까지 많은 에포크가 필요합니다.** 

```python
>>> y_pred = ppn.predict(X_test_std) #레이블 예측
>>> print('잘못 분류된 샘플 개수 : %d'%(y_test!=y_pred).sum())
잘못 분류된 샘플 개수 : 1
# 분류 오차 : 1/45 == 2.2%
```

분류오차 vs 정확도

분류 오차 대신 많은 머신러닝 기술자는 모델의 `분류 정확도`를 계산합니다.

1-오차 = 97.8%

사이킷런 라이브러리는 `metrics`모듈 아래에 다양한 **성능지표**를 구현해 놓았습니다. 예를 들어 데스트 데이터셋에서 퍼셉트론 분류 정확도는 다음과 같다.

```python
>>> from sklearn.metrics import accuracy_score
>>> print('정확도 : %.3f' % accuracy_score(y_test,y_pred))
정확도 : 0.978
#y_test가 진짜 레이블 클래스 y_pred는 예측 클래스 레이블
```

사이킷런의 분류기(classifier)는 예측 정확도를 계산하는 score메소드를 가지고 있다.

```python
print('정확도 : %.3f' % ppn.score(X_test_std,y_test))
# predict메소드와 accuracy_score메소드를 합친 것이다.
```

- **과대적합 : 훈련데이터에 있는 패턴은 감지하지만 본 적이 없는 데이터에 일반화 되지 못하는 것**  

- 퍼셉트론의 한계 : 선형적으로 레이블이 구분되지 않는다면 수렴되지 않는다.  전역 최솟값 수렴X. 비용함수 최소화를 하지 못한다.






