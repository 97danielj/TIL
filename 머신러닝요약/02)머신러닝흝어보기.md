# 02) 머신 러닝 훑어보기

## 1. 머신 러닝 모델의 평가**

![img](https://wikidocs.net/images/page/24987/%EB%8D%B0%EC%9D%B4%ED%84%B0.PNG)

머신 러닝을 위한 데이터를 준비했다면 기계를 학습하기 전 해당 데이터를 훈련용, 검증용, 테스트용 이렇게 세 가지로 분리하는 것이 일반적입니다. 훈련 데이터는 머신 러닝 모델을 학습하는 용도입니다. 테스트 데이터는 학습한 머신 러닝 모델의 성능을 평가하기 위한 용도입니다. 그렇다면 검증용 데이터의 용도는 무엇일까요?

검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라 **모델의 성능을 조정**하기 위한 용도입니다. 더 정확히는 모델이 훈련 데이터에 `과적합`이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도입니다. 하이퍼파라미터와 매개변수라는 용어를 정리해둡시다.

- 하이퍼파라미터(초매개변수) : 모델의 성능에 영향을 주는 사람이 값을 지정하는 변수
- 매개변수 : 가중치와 편향. 학습을 하는 동안 값이 계속해서 변하는 수

아직 이 장에서는 검증용 데이터와 하이퍼파라미터의 개념이 어떤 의미인지 와닿지 않아도 괜찮습니다. 이 개념은 앞으로 지속적으로 언급하게 될 것입니다. 이 두 변수의 가장 큰 차이는 하이퍼파라미터는 보통 사용자가 직접 정해줄 수 있는 변수라는 점입니다. 뒤의 선형 회귀에서 배우게 되는 경사 하강법에서 학습률(learning rate)이나, 딥 러닝에서 뉴런의 수나 층의 수와 같은 것들이 대표적인 하이퍼파라미터입니다.

반면, 가중치와 편향과 같은 매개변수는 사용자가 결정해주는 값이 아니라 모델이 학습하는 과정에서 얻어지는 값입니다. 훈련용 데이터로 훈련을 모두 시킨 모델은 **검증용 데이터**를 사용하여 정확도를 검증하며 **하이퍼파리미터를 튜닝**합니다. 검증용 데이터에 대해서 높은 정확도를 얻도록 하이퍼파라미터의 값을 바꿔보는 것입니다. 이렇게 튜닝하는 과정에서 모델은 검증용 데이터의 정확도를 높이는 방향으로 점차적으로 수정됩니다.

튜닝 과정을 모두 끝내고 **모델의 최종 평가**를 하고자 한다면, 이제 검증용 데이터로 모델을 평가하는 것은 적합하지 않습니다. 모델은 검증용 데이터의 정확도를 높이기 위해서 수정되어져 온 모델이기 때문입니다. **모델에 대한 평가**는 이제 모델이 한 번도 보지 못한 데이터인 테스트 데이터의 몫입니다. 수학능력시험을 준비하는 수험생으로 비유하자면 훈련 데이터는 실제 공부를 위한 문제지, 검증 데이터는 모의고사, 테스트 데이터는 실력을 최종적으로 평가하는 수능 시험이라고 볼 수 있습니다.



## **2. 분류(Classification)와 회귀(Regression)**

전부는 아니지만 머신 러닝의 많은 문제는 분류 또는 회귀 문제에 속합니다. 이번 챕터에서는 머신 러닝 기법 중 선형 회귀(Lineare Regression)과 로지스틱 회귀(Logistic Rgression)를 다루는데 선형 회귀는 대표적인 회귀 문제에 속하고, **로지스틱 회귀는 (이름은 회귀이지만) 대표적인 분류 문제에 속합니다.**

분류는 또한 이진 분류(Binary Classification)과 다중 클래스 분류(Multi-Class Classification)로 나뉩니다. 엄밀히는 다중 레이블 분류(Multi-lable Classification)라는 또 다른 문제가 존재하지만, 이 책에서는 이진 분류와 다중 클래스 분류만을 다룹니다.

### 1) 이진 분류 문제(Binary Classification)**

이진 분류는 주어진 입력에 대해서 두 **개의 선택지 중 하나의 답을 선택해야 하는 경우**를 말합니다. 종합 시험 성적표를 보고 최종적으로 합격, 불합격인지 판단하는 문제, 메일을 보고나서 정상 메일, 스팸 메일인지를 판단하는 문제 등이 이에 속합니다.

### 2) 다중 클래스 분류(Multi-class Classification)**

다중 클래스 분류는 주어진 입력에 대해서 세 개 이상의 선택지 중에서 답을 선택해야 하는 경우를 말합니다. 예를 들어 서점 직원이 일을 하는데 과학, 영어, IT, 학습지, 만화라는 레이블이 붙어있는 5개의 책장이 있다고 합시다. 새 책이 입고되면, 이 책은 다섯 개의 책장 중에서 분야에 맞는 적절한 책장에 책을 넣어야 합니다. 이 경우는 현실에서의 다중 클래스 분류 문제라고 할 수 있겠습니다.

### **3) 회귀 문제(Regression)**

회귀 문제는 분류 문제처럼 둘 중 하나를 선택해야 한다거나, 책이 입고되었을 때 5개의 책장 중 하나의 책장을 골라야하는 경우처럼 정답이 몇 개의 정해진 선택지 중에서 정해져 있는 경우가 아니라 **어떠한 연속적인 값의 범위 내에서 예측값이 나오는 경우**를 말합니다.

예를 들어서 역과의 거리, 인구 밀도, 방의 개수 등을 입력하면 부동산 가격을 예측하는 머신 러닝 모델이 있다고 해봅시다. 머신 러닝 모델이 부동산 가격을 7억 8,456만 3,450원으로 예측하는 경우도 있을 것이고, 8억 1257만 300원으로 예측하는 경우도 있을 수 있습니다. 특정 값의 범위 내에서는 어떤 숫자도 나올 수 있습니다. 기존의 분류 문제와 같이 분리된(비연속적인) 답이 결과가 아니라 **연속된 값을 결과로 가지는 이러한 문제를 회귀 문제**라고 부릅니다. 회귀 문제의 예시로 **시계열 데이터(Time Series Data)를 이용한 주가 예측, 생산량 예측, 지수 예측 등이 있습니다.**

## 3. 지도 학습과 비지도 학습**

머신 러닝은 크게 지도 학습, 비지도 학습, 강화 학습으로 나눕니다. 강화 학습은 이 책의 범위를 벗어나므로 설명하지 않습니다. 그리고 큰 갈래로서는 자주 언급 되지는 않지만 딥 러닝 자연어 처리에서 중요한 학습 방법 중 하나인 자기지도 학습(Self-Supervised Learning, SSL)에 대해서도 언급해보겠습니다.

### 1) 지도 학습(Supervised Learning)**

지도 학습이란 **레이블(Label)이라는 정답과 함께 학습하는 것**을 말합니다. 자연어 처리는 대부분 지도 학습에 속합니다. 앞으로 우리가 풀게 될 자연어 처리의 많은 문제들은 레이블이 존재하는 경우가 많기 때문입니다. 이는 앞서 2챕터의 데이터의 분리를 설명하며 상세히 설명한 바 있습니다. 레이블이라는 말 외에도 y, 실제값 등으로 부르기도 하는데 이 책에서는 이 용어들을 상황에 따라서 바꿔서 사용합니다. 기계는 예측값과 실제값의 차이인 오차를 줄이는 방식으로 학습을 하게 되는데 예측값은 $\hat{y}$과 같이 표현하기도 합니다.

### 2) 비지도 학습(Unsupervised Learning)**

**비지도 학습은 데이터에 별도의 레이블이 없이 학습하는 것**을 말합니다. 예를 들어 텍스트 처리 분야의 토픽 모델링 알고리즘인 LSA나 LDA는 비지도 학습에 속합니다. LSA와 LDA는 온라인 웹 사이트 위키독스의 e-book( https://wikidocs.net/30707 )에서 볼 수 있습니다.

### 3) 자기지도 학습(Self-Supervised Learning, SSL)**

**레이블이 없는 데이터가 주어지면, 모델이 학습을 위해서 스스로 데이터로부터 레이블을 만들어서 학습하는 경우를 자기지도 학습이라고 합니다.** 대표적인 예시로는 Word2Vec과 같은 워드 임베딩 알고리즘이나, BERT와 같은 언어 모델의 학습 방법을 들 수 있습니다. 이들이 어떻게 레이블을 만들어 학습하는지에 대한 설명은 Word2Vec과 BERT를 설명하는 페이지를 참고바랍니다.

## 4. 샘플(Sample)과 특성(Feature)**

많은 머신 러닝 문제가 1개 이상의 독립 변수 $x$를 가지고 종속 변수 $y$를 예측하는 문제입니다. 머신 러닝 모델 중 특히 인공 신경망은 독립 변수, 종속 변수, 가중치, 편향 등을 `행렬 연산`을 통해 연산하는 경우가 많습니다. 앞으로 인공 신경망을 배우게되면 훈련 데이터를 행렬로 표현하는 경우를 많이 보게 됩니다. 독립 변수 $x$의 행렬을 X라고 하였을 때, 독립 변수의 개수가 n개이고 데이터의 개수가 m인 행렬 X는 다음과 같습니다.

![img](https://wikidocs.net/images/page/35821/n_x_m.PNG)

이때 머신 러닝에서는 하나의 데이터. 행렬 관점에서는 하나의 행을 샘플(Sample)이라고 부릅니다. (데이터베이스에서 레코드라고 부르는 단위입니다.) 그리고 종속 변수 y를 예측하기 위한 각각의 독립 변수 x를 특성(Feature)이라고 부릅니다. 행렬 관점에서는 각 열에 해당됩니다.

## 5. 혼동 행렬(Confusion Matrix)**

머신 러닝에서는 맞춘 문제수를 전체 문제수로 나눈 값을 `정확도(Accuracy)`라고 합니다. 하지만 정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지는 않습니다. 이를 위해서 사용하는 것이 `혼동 행렬(Confusion Matrix)`입니다. 예를 들어 참(True)와 거짓(False) 둘 중 하나를 예측하는 문제였다고 가정해봅시다. 아래의 혼동 행렬에서 각 열은 예측값을 나타내며, 각 행은 실제값을 나타냅니다.

| -         | 예측 거짓 | 예측 참 |
| :-------- | :-------- | :------ |
| 실제 거짓 | TN        | FP      |
| 실제 참   | FN        | TP      |

머신 러닝에서는 다음과 같은 네 가지 케이스에 대해서 각각 TP, FP, FN, TN을 정의합니다.

- **True Positive(TP)** : 실제 True인 정답을 True라고 예측 (정답)
- **False Positive(FP)** : 실제 False인 정답을 True라고 예측 (오답)
- **False Negative(FN)** : 실제 True인 정답을 False라고 예측 (오답)
- **True Negative(TN)** : 실제 False인 정답을 False라고 예측 (정답)

이 개념을 사용하면 정밀도(Precision)과 재현율(Recall)이 됩니다.

### **1) 정밀도(Precision)**

정밀도란 모델이 True라고 분류한 것 중에서 실제 True인 것의 비율입니다.

$정밀도 = \frac{TP}{TP + FP}$

### 2) 재현율(Recall)

재현율이란 실제 True인 것 중에서 모델이 True라고 분류한 것 의의 비율

Precision이나 Recall은 **모두 실제 True인 정답을 모델이 True라고 예측한 경우**. 즉, TP에 관심이 있습니다. 두 식 모두 분자가 TP임에 주목합시다.

### 3) 정확도(Accuracy)

정확도는(Accuracy)는 우리가 일반적으로 실생활에서도 가장 많이 사용하는 지표입니다. 전체 예측한 데이터 중에서 정답을 맞춘 것에 대한 비율입니다.
$$
정확도 = \frac{TP+TN}{TP + FN+FP+TN}
$$
그런데 Accuracy로 성능을 예측하는 것이 적절하지 않은 때가 있습니다. 비가 오는 날을 예측하는 모델을 만들었다고 했을 때, 200일 동안 총 6일만 비가 왔다고 해봅시다. 그런데 이 모델은 200일 내내 날씨가 맑았다고 예측했습니다.  이 모델은 200번 중 총 6회 틀렸습니다. 194/200=0.97이므로 정확도는 97%입니다. 하지만 정작 비가 온 날은 하나도 못 맞춘 셈입니다.

또 다른 예를 들어봅시다. 스팸 메일을 분류하는 스팸 메일 분류기를 만들었습니다. 메일 100개 중 스팸 메일은 5개였습니다. 스팸 메일 분류기는 모두 정상 메일이라고 탐지했습니다. 정확도는 95%입니다. 그런데 정작 스팸 메일은 하나도 못 찾아낸 셈입니다.

이렇게 실질적으로 더 중요한 경우에 대한 데이터가 전체 데이터에서는 너무 적은 비율을 차지한다면 정확도는 좋은 측정 지표가 될 수 없습니다. 이런 경우에는 F1-Score를 사용합니다.



## **6. 과적합(Overfitting)과 과소 적합(Underfitting)**

학생의 입장이 되어 하나의 문제지를 과하도록 많이 풀어서 문제 번호만 봐도 정답을 맞출 수 있게 되었다고 가정합시다. 그런데 너무 오랜 시간 하나의 문제지만 반복해서 푼 나머지 다른 문제를 풀거나 시험을 봤을 때 점수가 안 좋다면 그게 의미가 있을까요?

머신 러닝에서 **과적합(Overfitting)** 이란 위의 비유처럼 훈련 데이터를 과하게 학습한 경우를 말합니다. 머신 러닝 모델이 학습에 사용하는 훈련 데이터는 실제로 앞으로 기계가 풀어야 할 현실의 수많은 문제에 비하면 극히 일부에 불과한 데이터입니다. 기계가 훈련 데이터에 대해서만 과하게 학습하면 성능 측정을 위한 데이터인 테스트 데이터나 실제 서비스에서는 정확도가 좋지 않은 현상이 발생합니다.

과적합 상황에서는 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 커집니다. 아래의 그래프는 과적합 상황에서 발생할 수 있는 훈련 데이터에 대한 훈련 횟수에 따른 훈련 데이터의 오차와 테스트 데이터의 오차(또는 손실이라고도 부릅니다.)의 변화를 보여줍니다.

![img](https://wikidocs.net/images/page/32012/%EC%8A%A4%ED%8C%B8_%EB%A9%94%EC%9D%BC_%EC%98%A4%EC%B0%A8.png)

 위 그래프는 뒤의 RNN을 이용한 텍스트 분류 챕터의 스팸 메일 분류하기 실습에서 훈련 데이터에 대한 훈련 횟수를 30 에포크로 주어서 의도적으로 과적합을 발생시킨 그래프입니다. y축은 오차(loss), X축의 에포크(epoch)는 전체 훈련 데이터에 대한 훈련 횟수를 의미하며, 사람으로 비유하면 동일한 문제지(훈련 데이터)를 반복해서 푼 횟수입니다. 에포크가 지나치게 크면 훈련 데이터에 과적합이 발생합니다.

스팸 메일 분류하기 실습은 에포크가 3~4에서 테스트 데이터에 대한 정확도가 가장 높고, 에포크가 그 이상을 넘어가면 과적합이 발생합니다. 위의 그래프는 에포크가 증가할수록 테스트 데이터에 대한 오차가 점차 증가하는 양상을 보여줍니다. 과적합은 다르게 설명하면 훈련 데이터에 대한 정확도는 높지만, 테스트 데이터는 정확도가 낮은 상황이라고 말할 수도 있습니다. 이런 상황을 방지하기 위해서는 **테스트 데이터의 오차가 증가하기 전이나, 정확도가 감소하기 전에 훈련을 멈추는 것이 바람직합니다.**

반면, 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태를 **과소적합(Underfitting)** 이라고 합니다. 과소 적합은 훈련 자체가 부족한 상태이므로 훈련 횟수인 에포크가 지나치게 적으면 발생할 수 있습니다. 과대 적합과는 달리 과소 적합은 훈련 자체를 너무 적게한 상태이므로 훈련 데이터에 대해서도 **정확도가 낮다는 특징**이 있습니다.

이러한 두 가지 현상을 과적합과 과소 적합이라고 부르는 이유는 머신 러닝에서 학습 또는 훈련이라고 하는 과정을 적합(fitting)이라고도 부르기 때문입니다. 모델이 주어진 데이터에 대해서 적합해져가는 과정이기 때문입니다. 이러한 이유로 케라스에서는 기계를 학습시킬 때 fit()을 호출합니다. 바로 뒤의 선형 회귀 실습에서 보게 될 것입니다.

딥 러닝을 할 때는 과적합을 막을 수 있는 **드롭 아웃(Dropout), 조기 종료(Early Stopping)**과 같은 몇 가지 방법이 존재하는데 이는 뒤의 딥 러닝 챕터에서 소개합니다.

과적합과 과소 적합을 설명하면서 테스트 데이터를 사용하여 판단할 수 있다고 설명하였지만, 더 정확히 설명하면 현업에서는 **테스트 데이터를 두 가지 용도로 분리**하여 사용하는 것이 더 바람직합니다. 각각의 용도는 **과적합 모니터링과 하이퍼파라미터 튜닝을 위한 테스트 데이터**와 오직 **성능 평가만을 위한 테스트 데이터**입니다. 그리고 전자의 테스트 데이터를 **검증 데이터**라고 부릅니다. 앞에서 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터 세 가지로 나누어야 한다고 언급했던 것을 기억하시나요? 과적합 방지를 고려한 일반적인 딥 러닝 모델의 학습 과정은 다음과 같습니다.

- Step 1. 주어진 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터로 나눈다. 가령, 6:2:2 비율로 나눌 수 있다.
- Step 2. 훈련 데이터로 모델을 학습한다. (에포크 +1)
- Step 3. 검증 데이터로 모델을 평가하여 검증 데이터에 대한 정확도와 오차(loss)를 계산한다.
- Step 4. 검증 데이터의 오차가 증가하였다면 과적합 징후이므로 학습 종료 후 Step 5로 이동, 아니라면 Step 2.로 재이동한다.
- Step 5. 모델의 학습이 종료되었으니 **테스트 데이터로 모델을 평가한다**.
