[toc]

# 언어모델

## 1. 개념

- **단어 시퀀스(문장)에 확률을 할당하는 모델을 말한다.**
- 크게 통계를 이용하는 방법과 인공 신경망, 음성인식을 이용한 방법
- **통계 기반한 언어 모델**은 실제 사용하는 **자연어를 근하기에는 많은 한계**가 있고, 요즘 들어 인공 신경망이 그러한 한계를 많이 해결해주면서 통계 기반 언어 모델을 사용하는 빈도가 줄었다.
- 언어라는 현상을 모델링하고자 단어 시퀀스(문장)에 확률을 할당하는 모델
- 언어 모델은 **가장 자연스러운 단어 시퀀스를 찾아내는 모델**
- **보편적으로 사용되는 방법은 언어 모델이 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 하는것**
- BERT는 양쪽 단어들로부터 가운데 단어 예측
- **언어 모델링 : 주어진 단어들로부터 아직 모르는 단어를 모르는 예측하는 작업**
- 문법이 하는일과 비슷하다. 해당 단어가 기존 문자시퀀스에 적합한지 안한지 판별하니



## 2. 단어 시퀀스의 확률

- 언어 모델 아래와 같이 확률을 통해 **보다 적절한 문장을 판단합니다.**

1. 기계 번역(Machine Translation)
   - P(나는 버스를 탔다) > P(나는 버스를 태운다)
     : 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단합니다.
2. 오타 교정(Spell Correction)
   - 선생님이 교실로 부리나케
     P(달려갔다) > P(잘려갔다)
     : 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단합니다.
3. 음성 인식(Speech Recognition)
   - P(나는 메롱을 먹는다) < P(나는 메론을 먹는다)
     : 언어 모델은 두 문장을 비교하여 우측의 문장의 확률이 더 높다고 판단합니다.



## **3. 주어진 이전 단어들로부터 다음 단어 예측하기**

- 언어 모델은 단어 시퀀스에 확률을 할당하는 모델입니다.

- 단어 시퀀스에 확률을 할당하기 위해서 가장 보편적으로 사용하는 방법은 이전 단어들이 주어졌을 때, 다음 단어를 예측하도록 하는 것입니다. 이를 조건부 확률로 표현해보겠습니다.

### **A. 단어 시퀀스의 확률**

하나의 단어를 w, 단어 시퀀스을 대문자 W라고 한다면, n개의 단어가 등장하는 단어 시퀀스 W의 확률은 다음과 같습니다.

- P(W) = P(w1, w2, w3, w4, w5, ..., wn)

### **B. 다음 단어 등장 확률**

다음 단어 등장 확률을 식으로 표현해보겠습니다. n-1개의 단어가 나열된 상태에서 n번째 단어의 확률은 다음과 같습니다.

- P(wn|w1 , ..., wn-1) : 이미 1~n-1가 나열이 된 상태에서 다음 단어로 wn이 나올 확률
- n번째 단어가 나올 확률은 n번째 조건부 확률이다.
- 기존의 단어를 바탕으로 만들어질 다음 단어의 확률
- 기존의 단어들의 정보=문맥정보
- P(W)는 각 단어의 조건부 확률의 곱이된다.

![image-20220510232019321](언어모델.assets/image-20220510232019321.png)
