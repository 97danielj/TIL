[toc]

# 웹크롤링

## 1. urllib으로 웹페이지 추출하기

* 웹페이지 추출할 때는 표준 라이브러리 urllib.request 모듈을 사용합니다.

|             함수명 / 필드명              |                             기능                             |     입력값      |                            반환값                            |
| :--------------------------------------: | :----------------------------------------------------------: | :-------------: | :----------------------------------------------------------: |
|                urlopen()                 |                        url을 가져온다                        |     url경로     |                  HTTPResponse객체->파일객체                  |
|           HTTPResponse.read()            |                 HTTP 응답 본문을 추출합니다.                 |        -        |                         bytes 자료형                         |
|           HTTPResponse.status            |                    상태코드를 추츨합니다.                    |                 |                           ex) 200                            |
|  HTTPResponse.getheader('Content-type')  |                 HTTP 헤더의 값을 추출합니다.                 |   출력 변수명   | 헤더의 내용을 변경하려거나 Basic인증 사용하려면  Requests 서드파티 라이브러리 필요 |
|           HTTPResponse.info()            |              HTTPResponse헤더의 전반적정보 출력              |                 |                       HTTPMessage객체                        |
| HTTPMessage.get_content_charset(failobj) | HTTP헤더를 기반으로 인코딩 방식 출력. 헤더에 해당 변수 값이 없는 경우 failobj문자열을반환 | failobj='utf-8' |                                                              |

## 2. 문자코드 다루기

- HTTPResponse.read()로 추출할 수 있는 응답본문의 값은 bytes자료형이므로 문자열(str자료형)으로 다루려면 문자코드를 지정해야한다.
- HTTP헤더에서 Content-type 헤더를 참조하면 해당 페이지에서 사용되고 있는 인코딩 방식을 알아낼 수 있습니다.
  - text/html
  - text/html; charset=UTF-8
  - text/html; charset=EUC-KR
  - charset= 뒤에 적혀 있는 문자열이 인코딩 방식입니다. default는 UTF-8
  - HTTPResponse.info()

## 3. meta 태그에서 인코딩 방식 추출하기

- HTTP헤더 인코딩 정보(웹서버 설정)와 실제 인코딩 형식이 다른경우

- 매타태크 또는 응답본문의 바이트 열도 확인해서 최종적인 인코딩 방식을 결정

  #meta태그의 charset 값에서 인코딩 방식을 추출한다.

  <meta charset="utf-8"></meta>
  <meta http-equiv="Content-Type" content="tent/html"; charset="EUC_KR"></meta>

  ```python
  scanned_text = bytes_content[:1024].decode('ascii',errors='replace')
  #응답 본문 앞부분 1024바이트를 ASCII문자로 디코딩해 둡니다.
  
  match = re.search(r'charset = ["\']\?([\w-]+)', scanned_text)
  #정규표현식으로 해당하는 charset값 추출
  
  if match: #해당 객체가 있다면
      encoding = match.group(1)
  else:
      encoding = 'utf-8'
  
  ```



## 4. 웹페이지에서 데이터 추출하기(스크레이핑)

* 정규표현식
  * HTML을 단순한 문자열 취급, 필요한 부분을 추출 합니다.
  * 제대로 마크업되지 않은 페이지도 문자열특징을 파악하여 쉽게 스크레이핑 가능
* XML파서
  * XML태그를 분석(파싱)하고, 필요한 부분만 추출합니다.
  * 블로그, 뉴스 사이트 정보를 전달하는 RSS처럼 많은 정보가 XML로 전달됩니다.
  * XML은 HTML보다 유연성이 떨어져 XML파서에 곧장 HTML을 넣어 분석은 불가능하다.

### 1. 정규표현식으로 스크레이핑 하기

* 표준 라이브러리 re 모듈을 사용한다.

* raw문자열이라 불리는(r'...')형식의 문자열 리터럴 사용하면 백슬레시가 이스케이프 문자로 사용되지 않습니다.

* ```python
  p = re.compile('ab*')
  #정규표현식을 컴파일
  #컴파일된 패턴 객체를 리턴
  ```

* 패턴객체 4가지 메서드

| 함수명 / 필드명 | 기능 | 입력값 | 반환값 |
| :---------: | :-----: | :----: | :----: |
| Pattern.match(str)  |        문자열의 처음부터 패턴과 매치되는지 조사한다.         |  str   | match / None<br>처음부터 일치하는지 검사하고 아니면 곧바로 return None |
| Pattern.search(str) |      문자열 전체를 검색하여 패턴과 매치되는지 조사한다.      |  str   | match / None<br>문자열 전체에서 검사하지만 제일처음 패턴과 매치되면 그 문자열과 매치된 정보만 가진 match만 return |
|  Pattern.findall()  |      정규식과 매치되는 모든 문자열을 리스트로 돌려준다       |  str   |                            리스트                            |
|  Patter.finditer()  | 정규식과 매치되는 모든 문자열을 반복 가능한 객체로 돌려준다. |  str   |           반복가능객체(match객체를 원소로 가진다.)           |

#### match 객체의 메서드

자, 이제 match 메서드와 search 메서드를 수행한 결과로 돌려준 match 객체에 대해 알아보자. 앞에서 정규식을 사용한 문자열 검색을 수행하면서 아마도 다음과 같은 궁금증이 생겼을 것이다.

- 어떤 문자열이 매치되었는가?
- 매치된 문자열의 인덱스는 어디서부터 어디까지인가?



match 객체의 메서드를 사용하면 이 같은 궁금증을 해결할 수 있다. 다음 표를 보자.

| method  | 목적                                                   |
| :------ | :----------------------------------------------------- |
| group() | 매치된 문자열을 돌려준다.                              |
| start() | 매치된 문자열의 시작 위치를 돌려준다.                  |
| end()   | 매치된 문자열의 끝 위치를 돌려준다.                    |
| span()  | 매치된 문자열의 (시작, 끝)에 해당하는 튜플을 돌려준다. |



## 5. 페이지 스크롤

### 1. scrollTo

```python
driver.execute_script("window.scrollTo(0, Y)")
#Y는 height를 입력하면 된다.
#페이지 끝까지 가려면 document.body.scrollHeigh사용
#계속 스크롤할려면 반복문을 사용
```



### 2. ActionChains 의 move_to_element

특정 element를 알고 있을 때 그 위치까지 scroll하게 됩니다.

```python
# ActionChains 를 사용하기 위해서.
from selenium.webdriver import ActionChains

# id가 something 인 element 를 찾음
some_tag = driver.find_element_by_id('something')
#요소를 찾았는지 체크를 하는게 좋다.

# somthing element 까지 스크롤
action = ActionChains(driver)
action.move_to_element(some_tag).perform()
```

코드에 'someting' element를 찾았는지 체크하는 것이 좋습니다. if문 하나 추가하면 된다.



### 3. 특정 시간동안 계속 scroll down하기

datetime을 이용해서 정해진 초 동안 1초에 한번씩 스크롤 다운합니다.

이 방법은 무한로딩 데이터를 다 가져올수는 없다. 적당히 가져와야 한다.

```python
import datetime #날짜와 시간 조작 클래스
def doScrollDown(whileSeconds):
    start = datetime.datetime.now()
    end = start+datetim.ti
```



