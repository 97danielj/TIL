## 11. 패딩(Padding)

- 병렬 연산을 위해서 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업
- 하나의 행렬로 만듬
- 기준 길이는 토큰화된 행렬에서 가장 긴 문장의 길이로 맞춘다.
- 채워주는 단어(가상의 단어)는 'PAD'라는 0번 정수 인덱스를 가지는 가상 단어를 사용

### 1. numpy 패딩

```python
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer()
tokenizer.fit_on_texts(preprocessed_sentences)
encoded = tokenizer.texts_to_sequences(preprocessed_sentences)
#인코딩

#최대길이
max_len = max(len(item) for item in encoded)

#제로패딩 : 0을 채워서 데이터의 크기를 조정
```

### 2. 케라스 전처리 도구로 패딩하기

- 기본적으로 앞에 0을 채운다.
- 앞에 채우고 싶으면 padding = 'post'

```python
from tensorflow.keras.preprocessing.sequence import pad_sequences
#케라스는 패딩을 위한 pad_sequence()를 제공하고 있습니다.

tk = Tokenizer()
tk.fit_on_texts(pr_data) #정수 인덱스 사전
encoded = tk.texts_to_sequences(pr_data) #인코딩
encoded

end_data=pad_sequences(encoded,padding='post') #encoded리스트를 행렬로 패딩. 기존데이터는 전방에
end_data

#뒤에서 단어 삭제
end_data2=pad_sequences(encoded,padding='post',truncating='post', maxlen=5)
#padding값을 바꿀시 존재하는 정수 인덱스와 겹치치 않게 정수를 부여한 후 value=v로 함수에 전달.
```

