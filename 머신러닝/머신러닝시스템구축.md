[toc]



# 머신러닝시스템 구축 로드맵

## 1. 전처리

- 데이터 추출 : 원본 데이터이서 필요한 특성을 추출
- 스케일링 조정 : 추출한 특성의 범위를 같게하거나 표준정규분포로 변환시킨다.
- 차원축소 : 중복된정보를 삭제하고, 시스템 자원을 아끼며, 모델의 예측성능도 올린다.
- 샘플링 : 훈련데이터와 테스트데이터의 분할
- 데이터의 품질 문제
  - 데이터분포의 지나친 차이 : 스케일을 맞춰줌
  - 범주형 데이터 
    - 원핫인코딩 : 범주형 데이터의 개수만 큼 가변수를 생성하여 존재 유무를 1 또는 0으로 표현
    - 판다스에서 제공하는 get_dummies함수
    - 사이킷런에서 제공하는 LabelEncoder나 OneHotEncoder사용

  - 결측치 : 실제 존재하지만 기록은 되지 않은 데이터
    - 드롭과 채우기
      - dropna()사용
      - fillna()

    - 평균값으로 채움
    - 확인시 isnull사용

  - 이상치 : 극단적으로 크거나 작은 값




## 2. 예측 모델 훈련과 선택

분류 알고리즘 저마다 태생적인 편향을 가지고 있습니다. 작업에서 아무런 가정도 하지 않는다면 어떤 뷴류 모델이 더 우월하다 정의 할 수 없습니다.

여러 모델을 비교하기전에 성능을 측정할 지표가 있어야 합니다.

분류에서 널리 사용되는 지표는 정확도입니다.

**정확도 : 분류 모델에서 정확히 분류된 샘플 비율**

모델 선택에서 테스트 데이터셋을 사용하지 않고 최종 모델을 평가하려 따로 보관 한다면 테스트 데이터와 실제 데이터에서 어떤 모델이 잘 동작할지 어떻게 알 수 있을까?

### 1.**교차 검증 기법 : **

모델 학습 시 데이터를 훈련용과 검증용으로 교차하여 선택하는 방법입니다. 일반적으로 K-Fold Cross Validation

1. **교차 검증 필요 이유 : 고정된 test set을 가지고 모델의 성능을 확인하고 파라미터를 수정하고, 이 과정을 반복하면 결구 내가 만든 모델은 testset에서만 잘 동작하는 모델이된다. 이경우 testset에 과적합이 되어 다른 실제 데이터를 가지고 예측 수행시 엉망이 결과가 나온다.**
2. 교차검증의 장단점

|                 장점                 |                         단점                         |
| :----------------------------------: | :--------------------------------------------------: |
|   특정 데이터셋에 대한 과적합 방지   |                                                      |
|     더욱 일반화된 모델 생성 가능     | 모델 훈련 및 평가 소요시간 증가(반복 학습 횟수 증가) |
| 데이터셋 규모가 적을시 과소적합 방지 |                                                      |

K-Fold Cross-Validation : 전체 데이터셋을 전체 데이터셋을 K개의 fold로 나누어 K번 다른 fold 1개를 test data로, 나머지 (K−1)개의 fold를 train data로 분할하는 과정을 반복함으로써 train 및 test data를 교차 변경하는 방법론 

3. 교차검증 절차

① 전체 데이터를 K개 fold로 분할
② 분할된 fold 중 test data로 할당된 적이 없는 fold 1개를 test data로 할당
③ 위 ② 과정을 K번 반복
④ K개의 모델 성능 평가 결괏값을 평균 내어 최종 결괏값으로 활용

4. 특징 

- K는 하이퍼파라미터로서 주로 5~10fold사용
- 최적의 K값을 찾기 위한 실험적 검증 필요
- 가장 일반적인 교차 검증 방법론



### 2. 하이퍼파라미터

모델 성능을 향상하기 위해 사용하는 다이얼. 사용자가 직접 세팅

머신 러닝 라이브러리들에서 제공하는 알고리즘의 기본 하이퍼파라미터가 현재 작업에 최적이라고 기대할 수 없습니다. 이에 하이퍼파라미터를 최적화하는 기법이 필요하다.

#### 하이퍼파라미터와 파리미터의 차이점

|                           파라미터                           |                 하이퍼파라미터                 |
| :----------------------------------------------------------: | :--------------------------------------------: |
|            모델 내부에서 결정(데이터로부터 결정)             |               사용자가 직접 세팅               |
|               사용자에 의해 조정되지 않습니다.               |            정해진 최적의 값은 없다.            |
| 선형회귀의 계수도 마찬가지 입니다. 수많은 데이터가 있고, 그 데이터에 대한 선형 회귀를 했을 때 계수가 결정됩니다. 모델링에 의해 자동으로 결정되는 값입니다. |                                                |
| 인공신경망의 가중치, SVM 서포트벡터, 선형회귀, 로지스틱회귀의 결정계수 | 학습률,손실함수,미니배치,에포크. 은닉층의 개수 |



## 3. 모델을 평가하고 본적 없는 샘플로 예측

훈련데이터셋에서 최적의 모델을 선택한 후에는 테스트 데이터셋을 사용하여 이전에 본 적 없는 데이터에서 얼마나 성능을 내는지 예측하여 일반화 오차를 예상합니다.  성능이 만족한다면 이 모델을 사용해 미래의 새로운 데이터를 예측한다.
